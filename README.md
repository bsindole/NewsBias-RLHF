# NEWSBIAS_RLHF: Mitigating Media Bias with Reinforcement Learning

The NEWSBIAS_RLHF project is a pioneering exploration into identifying and mitigating biases in news media through the advanced application of Reinforcement Learning from Human Feedback (RLHF) and transformer models. This project leverages a unique dataset that spans multiple dimensions of media bias, including political inclinations, hate speech, toxicity, sexism, and ageism, to train models that can understand and adjust for these biases, ensuring a more balanced and objective news media landscape.

## Key Features:

### Comprehensive Bias Analysis: 
Utilizes a meticulously curated dataset to analyze a broad spectrum of biases in news media.
### Advanced ML Techniques: 
Employs state-of-the-art machine learning methods, including transformers and RLHF, to effectively fine-tune models on the NEWS BIAS dataset.
### Impactful Outcomes: 
Aims to create tools and methodologies that media organizations and researchers can use to detect and mitigate bias, fostering a more informed and equitable public discourse.
## Technologies Used:

* Transformers for NLP tasks
* Reinforcement Learning from Human Feedback (RLHF) for model fine-tuning
* Weights & Biases (wandb) for experiment tracking
* TRL (Transformers Reinforcement Learning) library
* Pandas for data manipulation
* Hugging Face's datasets library for efficient data loading and preprocessing
* Accelerate for streamlined multi-GPU training
* Tyro for easy CLI interfaces
* NLTK for natural language processing tasks


## Project Objectives:
This project is designed to push the boundaries of how machine learning can be applied to address the critical issue of bias in news media. By developing models that can identify and mitigate various biases, NEWSBIAS_RLHF contributes to the development of a media landscape that upholds the principles of fairness, objectivity, and inclusivity.
